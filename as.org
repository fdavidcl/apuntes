#+TITLE: Arquitectura de Sistemas

* Tareas
** Ejercicios voluntarios
*** Resumen sobre [[http://www.anandtech.com/show/10025/examining-soft-machines-architecture-visc-ipc][VISC]]

*** IOMMU
Unidad de gestión de memoria específica para dispositivos de I/O. Resumen a mano.

*** Coste del cambio de contexto

Encontrar una comparativa entre distintos SO o SO de distinto tipo

*** Famosa discusión Torvalds-Tanenbaum

Resumen y visión crítica personal

* Teoría
** 1. Soporte hardware

**** Componentes

***** Memoria

****** Caché

****** Protección de memoria: memoria virtual

Memoria virtual: El procesador proporciona trozos de memoria "ficticios" que pueden ser mayores de la memoria disponible. Tipos:
- Segmentación
- Paginación

El respaldo de memoria que no esté disponible se realiza en disco.

La unidad de gestión de memoria (MMU) realiza la traducción de las direcciones virtuales a físicas.

Nota: cada instrucción x86 podría implicar varios accesos a memoria. Además de cada instrucción, alguno de los operandos puede estar en memoria.

Cada traducción de dirección puede llegar a tardar miles de ciclos de reloj. Además, el tamaño de una tabla de páginas completa podría ser muy larga, ya que se habilitan muchas más páginas virtuales que físicas.

*Solución en x86-64: tabla de páginas multinivel*

Se extraen trozos de 9 bits que dan la dirección base de la página del siguiente nivel, y así hasta llegar a la página de memoria buscada. Cada petición a una página tarda unos 100 ciclos, luego se pueden acumular unos 500 ciclos simplemente para pedir una dirección.

Para ahorrar tiempo, se almacena una table/caché de traducciones en memoria caché totalmente asociativa, muy cara pero muy rápida.

Al cambiar de programa se borran las cachés y por tanto la tabla de traducciones que había tardado miles de ciclos en crearse.

****** Buffer de traducción anticipada (TLB)

Una forma de "no tirar" una traducción almacenada en el TLB es etiquetarla con el proceso. Así se pueden mantener aun cambiando programas. Esto se suele hacer únicamente al trabajar con máquinas virtuales.

Puesto que las hebras sí comparten espacio de direcciones, y por tanto tabla de traducciones, es más común ahora programar grandes procesos con muchas hebras, que varios procesos (más lento al tener distintos espacios de direcciones).

****** Esquemas de direccionamiento de caché

Si tenemos una caché con direccionamiento virtual podemos buscar mayor rapidez sin pasar por el TLB para recuperar datos.

Las arquitecturas modernas implementan soluciones mixtas: los primeros niveles de caché suelen ser virtuales y los siguientes, físicos. (p53, 3ª figura)

***** Interacción

***** Entrada/salida

***** Excepciones e interrupciones

> Son un lío
> Son un follón
> Nadie sabe lo que son
> -- Gustavo, 2017

Excepciones:
 - ocurren dentro del procesador (e.g. división por cero)
 - son predecibles y reproducibles

Interrupciones:
 - ocurren fuera del procesador
 - no son predecibles ni reproducibles

No todas las excepciones son erróneas: por ejemplo, el fallo de página (la petición de un trozo de memoria que no está disponible), o los puntos de ruptura (insertados por depuradores)

****** La interrupción software: int, trap

Son esencialmente excepciones (lol).

****** Vector de interrupciones

Antiguamente contenía 256 entradas y se almacenaba en el primer KB de memoria. Ahora, hay un registro de procesador que indica dónde está almacenada, para permitir mayores tamaños y flexibilidad.

****** Temporización

Las interrupciones ocupan tiempo, en general no afectan a la ejecución de programas. Las aplicaciones de tiempo real no se pueden permitir interrupciones: por ejemplo, el reproductor de sonido que emite 44100 muestras de audio por segundo.

Soluciones
- deshabilitar las interrupciones
  - no funciona si se trabaja en un multiprocesador y otro proceso puede "meterse en nuestra memoria"
- ejecutar instrucciones atómicas (test-and-set, cmpxchg, ldl/stc)

El procesador puede enmascarar/deshabilitar las interrupciones y asignarles niveles de prioridad. Con esta última opción, por ejemplo un dispositivo rápido puede interrumpir a uno lento y no al contrario (e.g. la controladora de red interrumpe al controlador de teclado).

****** Procesamiento de interrupciones

- icall, iret llaman y vuelven del controlador software

****** Técnicas de E/S

- E/S programada (polling)
  - Se consulta continuamente un estado para comprobar novedades
- E/S mediante interrupción
  - Se obtiene un evento cuando el estado cambia
- Acceso directo a memoria
  - Se añade un chip independiente que conoce los trozos de memoria que debe enviar (y este se gestiona mediante interrupciones). Esto deja libre a la CPU.

****** Direccionamiento físico de la memoria principal

****** El temporizador

Ejemplo: en MS-DOS los procesos no podían ser interrumpidos (y sólo se podía cambiar de proceso cuando llamaban al sistema). Después se añadió la interrupción de temporizador periódica (y en cada una se comprueba si es conveniente cambiar de proceso, etc.).

Actualmente, el temporizador se reprograma tras cada evento. Por ejemplo, si no hay ninguna aplicación de tiempo real ejecutándose, se pueden hacer los trozos de tiempo más largos. Y si se ejecuta e.g. un reproductor de sonido, se programa el temporizador para activarse cuando se necesite enviar más datos a la tarjeta de sonido.

** 2. Introducción a los sistemas operativos

*** Abstracciones

Las tres abstracciones importantes en el ordenador:

1. Memoria/Espacio de direcciones/RAM
   Unidad de protección: elimina la capacidad para acceso en direcciones protegidas
   Secciones de memoria para un proceso:
   - .text (código)
   - .data (datos inicializados), .bss (datos sin inicializar)
   - heap 
   - stack: contiene una copia del instruction pointer (IP)
     incluye los marcos de procedimiento
     está situada al final de la memoria (por razones de falta de memoria en ordenadores antiguos)

2. Procesos, hebras, tareas
   El programa es la "receta", el proceso es el resultado, la instancia del programa en ejecución. Consta esencialmente de un espacio de direcciones y un puntero de instrucción (ip, %rip...)

3. Comunicación entre procesos
   Los libros describen 3 tipos: memoria compartida, paso de mensajes, ficheros (tuberías, sockets)

**** Concurrencia y paralelismo

Aprenderemos a gestionar y resolver condiciones de carrera

**** Gestión de memoria

A los programas los engañamos como a chinos:

***** Código relocalizable
código que se ejecuta exactamente igual independientemente de las direcciones en las que se ejecute.
***** Memoria virtual
Proporcionamos a los procesos más memoria de la realmente disponible. El mapeado de porciones de memoria virtual en memoria física se hace de forma automática.
Las regiones (páginas) no necesariamente son continuas. Las páginas se pueden guardar y recuperar de disco.

**** Planificación de recursos

Criterios: equidad, tiempo de respuesta, eficiencia.

Se suele distinguir entre políticas y mecanismos: paginación mediante despacho, paginación mediante reemplazo, interacción (entre procesos) mediante comunicación.

**** Gestión de E/S

Los controladores software proporcionan interfaces

- homogéneas (UNIX)
- específicas y heterogéneas (Windows)

Componentes de un controlador software:

- código de inicialización
- llamada al sistema
- manejador de interrupciones

**** Ficheros

Almacenamiento persistente:

- ficheros
- directorios (esencialmente, ficheros que contienen metadatos)

Tipos de ficheros:

- tradicionales: en disco, se gestionan mediante llamadas al sistema
- mapeados en memoria: viven en la memoria principal pero están montados en el sistema de ficheros. Se pierden si se desconecta la alimentación, pero se pueden ir volcando periódicamente a disco.

*** Llamadas al sistema

Se puede interactuar con el sistema (mediante llamadas) a través de APIs del sistema como Win32 o POSIX.

Para pasar los parámetros se usaba tradicionalmente la pila, actualmente se suele usar el conjunto de registros.

** 3. Historia de los sistemas operativos

> Rápido o seguro. Los dos a la vez no.
> Habrá gente que diga que sí se puede. No se puede.
> --Gustavo, 2017

*** Historia

**** Primera generación

Eran una calculadora gorda. Formados por dispositivos mecánicos. Programados al principio con cables, y luego pasaron a interruptores y tarjetas perforadas.

Sólo eran capaz de usarlos los que los habían diseñado y construido.

**** Segunda generación

Aparición de los transistores. Época de los mainframes.

Programación en ensamblador y Fortran... sobre tarjetas perforadas.

Sistemas operativos: FMS, IBSYS.

**** Tercera generación

Además de cálculo, empiezan a utilizarse para procesamiento de caracteres (bases de datos...).

SOs: OS/360, CTSS, MULTICS, UNIX

Logros:

- multiprogramación
- spooling
- tiempo compartido

**** Cuarta generación

Transistores más pequeños y baratos => popularidad.

IBM PC

Logros:
- GUI
- Comunicaciones: SO con red
- SMP
- SO distribuidos

SOs: UNIX, CP/M, MS-DOS, Linux, macOS, Windows

*** Estructura

Lo que más ha cambiado a lo largo del tiempo es la relación entre el precio de un ordenador y el precio del tiempo de las personas (aka sueldo).

**** Monolíticos

El SO completo se ejecuta como un único programa, en modo protegido. No hay protección entre componentes. No hay cambios de contexto.

Inconvenientes: menos fiable (controladores) y más complejo

**** Capas / Niveles

> Ni dios tiene ni idea de cuántas capas poner. Ni dios tiene ni idea de qué poner en cada capa.

Sólo evita la complejidad del monolítico, pero lo hace menos flexible.

**** Modular

Escasa protección.

> Ni dios tiene ni idea de qué colocar en el núcleo y qué en módulos

**** Micronúcleo

El micronúcleo es lo único que se ejecuta en modo protegido => muy fiable

Los componentes tienen que cooperar entre ellos a través del micronúcleo => menor eficiencia.

- Micronúcleo menos 'puro': se implementa un SO "de biblioteca" en plan monolítico pero en modo usuario.

**** Exonúcleo

Sólo aplicada en SO experimentales antiguos.

El exonúcleo es un gestor de recursos, asigna porciones de disco, memoria y CPU a cada proceso.

**** Máquina virtual

Las máquinas virtuales más sencillas son esencialmente programas que traducen instrucción a instrucción de una arquitectura a otra.

Una complicación es simular hardware (e.g. simular los dispositivos de un teléfono móvil)

La "máquina virtual" de Java traduce el bytecode (una abstracción sobre la arquitectura de un ordenador) a instrucciones reales. El bytecode se puede precompilar para la arquitectura concreta donde se va a ejecutar.

Las máquinas como VMWare o Virtualbox tratan de traducir lo menos posible. Esencialmente traducen llamadas al sistema.

**** Híbrida

Mezcla frecuente: micronúcleo + monolítico

Trata de ser un término medio entre ambos. Algunos componentes se incluyen en el micronúcleo para aumentar la velocidad.

*** Ejemplos

**** MS-DOS

Cualquier proceso se comunica directamente sobre el hardware.

"El wordperfect incluía sus propios controladores de impresora!"

**** Windows 2000 (NT)

Empezó como un desarrollo de tipo microkernel, se acabaron incluyendo componentes hasta dejarlo prácticamente monolítico.

**** Linux

Es monolítico, con módulos que se pueden activar y desactivar.

**** Mach

Micronúcleo. No tuvo éxito comercial

**** OS X

Frankenstein Mach + BSD.

**** QNX

Microkernel(o monolítico?) de verdad que se utiliza en sistemas empotrados y va muy rápido. De los comerciales, el único con cierto éxito. Implementa un mecanismo de resurrección: si un servicio se cae, lo mata y arranca otro nuevo.

*** Comparativa

> Atravesar la línea roja es la muerte
> --Gustavo, 2017

- Las llamadas al sistema de los micronúcleos son mucho más rápidas que en monoliticos, del orden de 5 a 1. El problema es que, en la práctica, los servidores suelen requerir muchas llamadas entre sí.

- L4 es un micronúcleo que sí es capaz de compensar el número de llamadas. L4Linux es Linux como SO de biblioteca montado sobre el micronúcleo L4 y proporciona prácticamente el mismo rendimiento. No está claro por qué no se han sustituido ya los sistemas monolíticos por micronúcleos.


** 4. Procesos

/copy on write/ copiar sólo cuando escribimos algo diferente. Sirve para hacer /forks/ de un proceso.

Con la señal =break= se aumenta la memoria dinámica de forma consecutiva. Con =nmap= no tiene por qué ser consecutiva.

El canario es una medida de seguridad, un código que se deja en memoria y se comprueba que se conserve (evitar procesos maliciosos que hagan /buffer overrun/ o similar).

*** Control

La ejecución de SO más común es "Ejecución *dentro* del los procesos de usuario"

*** Estado

** 5. Hebras

*** Introducción

Tiene ventajas separar el *contenedor de recursos* de la *hebra de ejecución*. El proceso se encarga de agrupar recursos y las hebras son entidades planificables.

En un proceso multihebra sólo es necesario un bloque de control de procesos (PCB), en 3 procesos con 1 hebra necesitamos 3 de ellos. La estructura de control de hebras es el TCB (en ambos casos se necesitan 3).

En un sistema multiprocesador las hebras se pueden ejecutar en *paralelo*, mientras que con un procesador se alternarán.

Cooperación: se usan hebras para aprovechar los trabajos realizados unas de otras. Si no fuera necesaria la cooperación se montarían programas independientes. Las hebras no se protegen entre sí porque teóricamente no es necesario, y no se pueden ocultar cosas (sí pueden! Thread Local Storage - variables privadas en la zona de datos).

Estados: se utilizan los mismos que en procesos. No se añade el estado *suspendido* porque se suspende a nivel de proceso.

Espacio de direcciones: cada hebra tiene su pila, IP e SP. Las pilas normales tienen 4K u 8K. En la práctica se colocan aleatoriamente en el espacio del proceso.

El identificador único de hebra puede ser global (normalmente es así) o único por proceso.

Cuando se forkea un proceso multihebra, ¿se copian todas las hebras al hijo? En Linux no porque no distingue procesos y hebras. En otros SO sí.

*** Tipos

**** Tipo usuario

Fueron las primeras que aparecieron. Consiste en colocar el sistema de hebras en el proceso. El SO no tiene ni idea de ellas.

sistema de ejecución de hebras = biblioteca de nuestro lenguaje favorito

Pueden implementarse en cualquier SO y la conmutación es mucho más rápida que la de procesos.

Inconvenientes: no hay paralelismo! Las llamadas al sistema bloquean todas las hebras

**** Tipo núcleo

En algunos SO no se distingue entre procesos y hebras: en Linux se llaman *tasks*.

La gestión se hace via llamadas al sistema => mayor coste.

Reciclaje de hebras: una hebra puede terminar y, si se pide otra, ser "renovada" para usarla.

**** Híbridas

Hebras tipo usuario multiplexadas sobre hebras tipo núcleo. No las usa ni dios.

*** Representación

| TCB mı́nimo                   |
|------------------------------|
| identificador de hebra (TID) |
| puntero de instrucción (IP)  |
| puntero de pila (SP)         |
| estado (flags)               |

Normalmente se representan en árboles

*** Ejemplos

**** Windows

Reparte la estructura entre núcleo y usuario.

**** Linux

No distingue: *task*.

Uso de =clone=.

**** Bibliotecas

- POSIX Pthreads
- Win32
- Java

** 6. Cambio de hebra

*** Voluntario

- Hay una pila por hebra. Porque es lo más cómodo.

*** Involuntario

En Linux las interrupciones se dividen en:
- top half: llevan la 'contabilidad' de la interrupción, registran todo lo necesario para preparar la consecución de la interrupción
- bottom half: procesamiento de la interrupción, no es urgente y puede ser interrumpido => permite anidar interrupciones (pero la top half hay que procesarla por completo siempre)

Las excepciones anidadas suelen indicar fallos en el sistema operativo (ya que el manejador de la excepción primera ya se ejecuta en el SO) => se pueden permitir 2 excepciones anidadas (e.g. para fallos de página)

Al usar =int= e =iret= frente a =call= y =ret= se guarda algo más del estado del procesador (la palabra de estado?).

En 64 bit tenemos instrucciones equivalentes =syscall= =sysret=, =sysenter= =sysexit=.

Estudio de la pila en detalle: esta vez se usan las instrucciones de =call= y =ret= por el sistema, y las =int= y =iret= (o equivalentes) por la hebra (??).

**** Finalización

Para finalizar una hebra y tener algún sitio al que volver, se incluye una hebra /ociosa/ que siempre es ejecutable. Esta hebra no hace cosas que no puedan bloquearla (e.g. un bucle infinito con =halt= o tareas de baja prioridad). El momento en que se introduce en el sistema depende del SO.

**** Inicialización

Al inicializar una hebra, nos "inventamos" su pila y la rellenamos como si hubiera ejecutado su parte de exit/yield.

**** Ventajas e inconvenientes

"Podemos hacer que el propio núcleo se implemente de forma multihebra" -> No se pone en práctica nunca.

** 7. Activación
*** Estados
Si tenemos más de una hebra y una cola centralizada => son necesarios estados

*afinidad*: último procesador en el que se ejecutó la hebra. Se intenta repetir procesador para no repetir el rellenado de la caché y el TLB

*estado interno*: una hebra cambia su estado a lo largo de su ejecución

*estado externo*: la relación de una hebra respecto a otras y con el sistema
- ejecutando
- preparada
- bloqueada

*** Modelos

**** Modelo 1 estado

Sólo válido con 1 procesador

**** Modelo 2 estados

Muy primitivo. Representa un sistema estático.

**** Modelo 3 estados

El estado /bloqueado/ se suele desglosar en muchos /mini estados/ para cada tipo de evento. Es más eficiente así. No está claro cómo subdividirlos.

**** Modelando E/S como hebras

No es muy común, se utiliza en un par de sistemas experimentales micronúcleos.

Bloqueado: esperando a la siguiente petición --> ejecutando: resolución de la petición -\
 ^--------------------------------------------------------------------------------------/

**** Modelo de 5 estados

Otros estados útiles:
- nuevo
- finalizado

**** Windows: 7 estados

Tienen los 5 estados anteriores.

Preparado, en espera y ejecutando son listas *por procesador*.
Los demás son globales para todos los procesadores.

"en espera" permite tener prevista la siguiente hebra a ejecutar de antemano.

De ejecutando se suele volver a preparado en el mismo procesador salvo que se necesite balanceo de carga o cualquier otro problema del estilo.

**** Intercambio/swap

*hiperpaginación*: se realiza tanto cambio de página e I/O con disco para cambiar de hebras y procesos que se ocupa la mayor parte del tiempo, sin ejecutar nada útil.

*** Implementación

**** del estado

Se suele utilizar estructura de árbol

***** como atributo del TCB

***** como estructura de datos

Mucho más eficiente

**** con punteros dentro/fuera del TCB

Si están fuera, la caché posiblemente se llena de muchos punteros poco útiles

**** Hebras y procesos

Los estados de las hebras tipo núcleo están relacionados con los procesos a los que pertenecen. Los estados de las hebras tipo usuario son independientes del de su proceso.

*** Cooperación

** 8. Sincronización

> La gente que escribe depuradores no tiene estatuas en las
> rotondas, pero deberían hacérselas. --Gustavo, 2017


*** Introducción

Cuidao con los recursos que se pasan por punteros y están almacenados en la pila o en el heap!

=volatile= le dice al compilador "No te fíes de esta variable, alguien la trastea". No es buen truco para solucionar problemas de paralelismo.

> ¿Los cuartos de baño no son reentrantes? --Gustavo, 2017

*** Señales

En general siempre nos va a interesar evitar la espera ocupada. La única excepción es que la espera ocupada vaya a tardar menos que el cambio de hebra.

Diapo. 44: interbloqueo! si el contador se modifica desde otra hebra entre =if(contador)= y =bloquear=.

El hecho de que se pierdan señales es beneficioso cuando se realizan de forma acumulativa, por ejemplo señales al planificador en interrupciones anidadas.

Señales con pérdida = banderas o semáforos binarios

Señales sin pérdida = semáforos con contador

Diapo 63: posibilidad de interbloqueo en las asignaciones a =valor=

* Prácticas

** 1. Entorno de desarrollo

> En el binario está la verdad, los unos y ceros
> --Gustavo, 2017

`strip` sirve para eliminar todo lo innecesario de un ejecutable y reducir así su tamaño.

`nm` revela los símbolos de un ejecutable y `c++filt` traduce los nombres a funciones de c++

`nm pienso2 | c++filt`

`ulimit` nos indica y modifica los límites de nuestro sistema
`ulimit -c unlimited` para generar corse

> El compilador hace cosas raras. Recordadlo
> --Gustavo, 2017

*** GDB

*Puntos de ruptura condicionales:*
`break bug.cc:12 if f == i`

** 2. Sector de arranque

- .code16: indicamos que el código es de 16 bits
- -Ttext 0x7C00: colocamos nuestro "programa" para ser ejecutado en la dirección 0x7c00
- la firma: el bootloader debe terminar (los últimos 2 bytes) en 0xaa55
- no queremos un binario ELF, sino normalito: --oformat binary

** 3. El teclado del PC

** 6. Hebras II

Los microprocesadores modernos vienen con multitud de registros, algunos de los cuales sirven para análisis de rendimiento. Los programas =oprofile= y =perf= permiten aprovecharlos para analizar procesos.
